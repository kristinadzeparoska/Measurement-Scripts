{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "hB2UwD9T2Avh"
      ],
      "authorship_tag": "ABX9TyO8qnetxISQyh39uvjwQRCd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Kris-D/Measurement-Scripts/blob/master/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bG4rUlFxD65"
      },
      "source": [
        "$Declarative Policy = ( D, E, A, C )$ \n",
        "\n",
        "$C=${ $ R, T, S$ }\n",
        "\n",
        "$R=[(r_0,m_0), ..., (r_k,m_k)]$ , \n",
        "$T= ${$t_0, .. t_k$} , \n",
        "$S = ${$s_0, ..., s_k$}\n",
        "\n",
        "R list of tuples ($r,m$), where $m$ contains key-value pairs, ex. $r_0$ has $m_0 = (m_{01},m_{02}...m_{0L})$ where $m_{01}$ --> resource type, example: infrastructure resources (e.g. network, compute, storage), user, and policy.\n",
        "\n",
        "    resource_type = {'network':['link','node'], 'compute': ['server','VM'], 'storage': ['database'], 'user':['admin'], 'policy':['policy'] }\n",
        "\n",
        "In use-case below, Constraint is:\n",
        "\n",
        "```\n",
        "Constraint = {[(link, {resource_type: network,..}), ((d2,e2,a2,c2),{resource_type:policy, ..}])} where c2={[(link, {resource_type:network,..})]}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rUeMeVRa3ZM6"
      },
      "source": [
        "    { 'Action':'minimize',\n",
        "      'Definer':'Admin_1',\n",
        "      'Enforcer':'App_1'\n",
        "      'Constraint': {\n",
        "        'Resource': \n",
        "            [('link', {'resource_type':'network', 'type':'edge', 'util':['max', <function _operator.le>, '45'] }),\n",
        "             ({'Definer':'Admin_1', \n",
        "              'Enforcer':'App_1', \n",
        "              'Action':'minimize', \n",
        "              'Constraint': { \n",
        "                'Resource': \n",
        "                    ['link', {'resource_type':'network' ,'type':'core', 'util':['max', <function _operator.le>, '70'] } ] \n",
        "                            } \n",
        "             }, {'resource_type': 'policy'}) \n",
        "            ]\n",
        "                    }\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hB2UwD9T2Avh"
      },
      "source": [
        "# Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfNZZ1ne5Zus",
        "outputId": "62ac4ac6-5206-4727-cfd3-cef23514d13e"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('stopwords')\n",
        "from nltk.stem.porter import PorterStemmer \n",
        "from nltk.stem.wordnet import WordNetLemmatizer \n",
        "from nltk.tokenize import word_tokenize \n",
        "import re\n",
        "import itertools\n",
        "from string import punctuation\n",
        "from nltk.corpus import stopwords  \n",
        "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
        "from operator import le, ge, lt, gt, eq, ne, truth\n",
        "import networkx as nx\n",
        "from networkx.drawing.nx_pydot import *\n",
        "import random\n",
        "import copy\n",
        "import pydot\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class bcolors:\n",
        "    HEADER = '\\033[95m'\n",
        "    OKBLUE = '\\033[94m'\n",
        "    OKGREEN = '\\033[92m'\n",
        "    WARNING = '\\033[93m'\n",
        "    FAIL = '\\033[91m'\n",
        "    ENDC = '\\033[0m'\n",
        "\n",
        "    def disable(self):\n",
        "        self.HEADER = ''\n",
        "        self.OKBLUE = ''\n",
        "        self.OKGREEN = ''\n",
        "        self.WARNING = ''\n",
        "        self.FAIL = ''\n",
        "        self.ENDC = ''"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}